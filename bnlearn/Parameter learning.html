

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Parameter learning &mdash; bnlearn bnlearn documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Inference" href="Inference.html" />
    <link rel="prev" title="Structure learning" href="Structure learning.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> bnlearn
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="Installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Installation.html#validate">Validate</a></li>
<li class="toctree-l1"><a class="reference internal" href="Installation.html#uninstalling">Uninstalling</a></li>
</ul>
<p class="caption"><span class="caption-text">Quickstart</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Quickstart.html">Quickstart</a></li>
</ul>
<p class="caption"><span class="caption-text">Methods</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Structure learning.html">Structure learning</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Parameter learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#maximum-likelihood-estimation">Maximum Likelihood Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bayesian-parameter-estimation">Bayesian Parameter Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#examples-parameter-learning">Examples Parameter learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#example-parameter-learning-1">Example Parameter learning 1</a></li>
<li class="toctree-l3"><a class="reference internal" href="#example-parameter-learning-2">Example Parameter learning 2</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="Sampling and datasets.html">Sampling and datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="Create DAG.html">Directed Acyclic Graphs</a></li>
</ul>
<p class="caption"><span class="caption-text">Additional Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="API Reference.html">API Reference</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">bnlearn</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Parameter learning</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/Parameter learning.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="parameter-learning">
<h1>Parameter learning<a class="headerlink" href="#parameter-learning" title="Permalink to this headline">¶</a></h1>
<p>Parameter learning is the task to estimate the values of the conditional probability distributions (CPDs).
To make sense of the given data, we can start by counting how often each state of the variable occurs.
If the variable is dependent on the parents, the counts are done conditionally on the parents states,
i.e. for seperately for each parent configuration.</p>
<p>Currently, the library supports Parameter learning for <em>discrete</em> nodes:</p>
<blockquote>
<div><ul class="simple">
<li><p>Maximum Likelihood Estimation</p></li>
<li><p>Bayesian Estimation</p></li>
</ul>
</div></blockquote>
<div class="section" id="maximum-likelihood-estimation">
<h2>Maximum Likelihood Estimation<a class="headerlink" href="#maximum-likelihood-estimation" title="Permalink to this headline">¶</a></h2>
<p>A natural estimate for the CPDs is to simply use the <em>relative frequencies</em>, with which the variable states have occured.</p>
<p>While very straightforward, the ML estimator has the problem of <em>overfitting</em> to the data.
If the observed data is not representative for the underlying distribution, ML estimations will be extremly far off.
When estimating parameters for Bayesian networks, lack of data is a frequent problem.
Even if the total sample size is very large, the fact that state counts are done conditionally for each parents configuration causes immense fragmentation.
If a variable has 3 parents that can each take 10 states, then state counts will be done seperately for <cite>10^3 = 1000</cite> parents configurations.
This makes MLE very fragile and unstable for learning Bayesian Network parameters.
A way to mitigate MLE’s overfitting is <em>Bayesian Parameter Estimation</em>.</p>
</div>
<div class="section" id="bayesian-parameter-estimation">
<h2>Bayesian Parameter Estimation<a class="headerlink" href="#bayesian-parameter-estimation" title="Permalink to this headline">¶</a></h2>
<p>The Bayesian Parameter Estimator starts with already existing prior CPDs, that express our beliefs about the variables <em>before</em> the data was observed.
Those “priors” are then updated, using the state counts from the observed data.</p>
<p>One can think of the priors as consisting in <em>pseudo state counts</em>, that are added to the actual counts before normalization. Unless one wants to encode specific beliefs
about the distributions of the variables, one commonly chooses uniform priors, i.e. ones that deem all states equiprobable.</p>
<p>A very simple prior is the so-called <em>K2</em> prior, which simply adds “1” to the count of every single state.
A somewhat more sensible choice of prior is <em>BDeu</em> (Bayesian Dirichlet equivalent uniform prior).
For BDeu we need to specify an <em>equivalent sample size</em> “N” and then the pseudo-counts are the equivalent of having observed <cite>N</cite> uniform samples of each variable (and each parent configuration).</p>
</div>
<div class="section" id="examples-parameter-learning">
<h2>Examples Parameter learning<a class="headerlink" href="#examples-parameter-learning" title="Permalink to this headline">¶</a></h2>
<div class="section" id="example-parameter-learning-1">
<h3>Example Parameter learning 1<a class="headerlink" href="#example-parameter-learning-1" title="Permalink to this headline">¶</a></h3>
<p>For this example, we will be investigating the sprinkler data set. This is a very simple data set with 4 variables and each variable can contain value [1] or [0].
The question we can ask: What are the parameters for the DAG given a dataset? Note that his data set is already pre-processed and no missing values are present.
We need both a directed acycle graph (DAG) and dataset with the same variables. The idea is to link the dataset with the DAG.</p>
<p>Let’s bring in our dataset.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">bnlearn</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">bnlearn</span><span class="o">.</span><span class="n">import_example</span><span class="p">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
<table class="docutils align-default">
<colgroup>
<col style="width: 21%" />
<col style="width: 29%" />
<col style="width: 16%" />
<col style="width: 34%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Cloudy</p></th>
<th class="head"><p>Sprinkler</p></th>
<th class="head"><p>Rain</p></th>
<th class="head"><p>Wet_Grass</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even"><td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
</tr>
<tr class="row-even"><td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
</tr>
</tbody>
</table>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">DAG</span> <span class="o">=</span> <span class="n">bnlearn</span><span class="o">.</span><span class="n">import_DAG</span><span class="p">(</span><span class="s1">&#39;sprinkler&#39;</span><span class="p">,</span> <span class="n">CPD</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">DAG</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils align-default">
<colgroup>
<col style="width: 23%" />
<col style="width: 17%" />
<col style="width: 23%" />
<col style="width: 15%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"></th>
<th class="head"><p>Cloudy</p></th>
<th class="head"><p>Sprinkler</p></th>
<th class="head"><p>Rain</p></th>
<th class="head"><p>Wet_Grass</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Cloudy</p></td>
<td><p>False</p></td>
<td><p>True</p></td>
<td><p>True</p></td>
<td><p>False</p></td>
</tr>
<tr class="row-odd"><td><p>Sprinkler</p></td>
<td><p>False</p></td>
<td><p>False</p></td>
<td><p>False</p></td>
<td><p>True</p></td>
</tr>
<tr class="row-even"><td><p>Rain</p></td>
<td><p>False</p></td>
<td><p>False</p></td>
<td><p>False</p></td>
<td><p>True</p></td>
</tr>
<tr class="row-odd"><td><p>Wet_Grass</p></td>
<td><p>False</p></td>
<td><p>False</p></td>
<td><p>False</p></td>
<td><p>False</p></td>
</tr>
</tbody>
</table>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">bnlearn</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">DAG</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-default" id="id1">
<span id="fig-pl"></span><img alt="_images/fig_sprinkler_sl.png" src="_images/fig_sprinkler_sl.png" />
<p class="caption"><span class="caption-text">DAG of the prinkler data set.</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
<p>Suppose we observed <strong>N</strong> “cloudy” occurences among a total of “all clouds”, so we might guess that about “50%” of “cloudy” are “sprinkler” or so.
According to MLE, we should fill the CPDs in such a way, that P(data|model) is maximal. This is achieved when using the <em>relative frequencies</em>.
From the <em>bnlearn</em> library, we’ll need the <a class="reference internal" href="bnlearn.parameter_learning.html#bnlearn.parameter_learning.fit" title="bnlearn.parameter_learning.fit"><code class="xref py py-class docutils literal notranslate"><span class="pre">fit</span></code></a> for this exercise:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">DAG_update</span> <span class="o">=</span> <span class="n">bnlearn</span><span class="o">.</span><span class="n">parameter_learning</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">DAG</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
<dl>
<dt>CPD of Cloudy:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 61%" />
<col style="width: 39%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Cloudy(0)</p></th>
<th class="head"><p>0.494</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Cloudy(1)</p></td>
<td><p>0.506</p></td>
</tr>
</tbody>
</table>
</dd>
<dt>CPD of Sprinkler:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 38%" />
<col style="width: 35%" />
<col style="width: 27%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Cloudy</p></th>
<th class="head"><p>Cloudy(0)</p></th>
<th class="head"><p>Cloudy(1)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Sprinkler(0)</p></td>
<td><p>0.48</p></td>
<td><p>0.70</p></td>
</tr>
<tr class="row-odd"><td><p>Sprinkler(1)</p></td>
<td><p>0.51</p></td>
<td><p>0.29</p></td>
</tr>
</tbody>
</table>
</dd>
<dt>CPD of Rain:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 29%" />
<col style="width: 35%" />
<col style="width: 35%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Cloudy</p></th>
<th class="head"><p>Cloudy(0)</p></th>
<th class="head"><p>Cloudy(1)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Rain(0)</p></td>
<td><p>0.65</p></td>
<td><p>0.33</p></td>
</tr>
<tr class="row-odd"><td><p>Rain(1)</p></td>
<td><p>0.34</p></td>
<td><p>0.66</p></td>
</tr>
</tbody>
</table>
</dd>
<dt>CPD of Wet_Grass:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Rain</p></th>
<th class="head"><p>Rain(0)</p></th>
<th class="head"><p>Rain(0)</p></th>
<th class="head"><p>Rain(1)</p></th>
<th class="head"><p>Rain(1)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Sprinkler</p></td>
<td><p>Sprinkler(0)</p></td>
<td><p>Sprinkler(1)</p></td>
<td><p>Sprinkler(0)</p></td>
<td><p>Sprinkler(1)</p></td>
</tr>
<tr class="row-odd"><td><p>Wet_Grass(0)</p></td>
<td><p>0.75</p></td>
<td><p>0.33</p></td>
<td><p>0.25</p></td>
<td><p>0.37</p></td>
</tr>
<tr class="row-even"><td><p>Wet_Grass(1)</p></td>
<td><p>0.24</p></td>
<td><p>0.66</p></td>
<td><p>0.74</p></td>
<td><p>0.62</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>
<p>Great! We have the probabilities! Lets check how much they differ from the truth.
In general it can be seen that the estimated values are not very close at every point to the true values.
The main reason is because the dataframe only contains 1000 samples.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">DAG_true</span> <span class="o">=</span> <span class="n">bnlearn</span><span class="o">.</span><span class="n">import_DAG</span><span class="p">(</span><span class="s1">&#39;sprinkler&#39;</span><span class="p">,</span> <span class="n">CPD</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<dl>
<dt>CPD of Cloudy:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 69%" />
<col style="width: 31%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>Cloudy(0)</p></td>
<td><p>0.5</p></td>
</tr>
<tr class="row-even"><td><p>Cloudy(1)</p></td>
<td><p>0.5</p></td>
</tr>
</tbody>
</table>
</dd>
<dt>CPD of Sprinkler:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 39%" />
<col style="width: 31%" />
<col style="width: 31%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>Cloudy</p></td>
<td><p>Cloudy(0)</p></td>
<td><p>Cloudy(1)</p></td>
</tr>
<tr class="row-even"><td><p>Sprinkler(0)</p></td>
<td><p>0.5</p></td>
<td><p>0.9</p></td>
</tr>
<tr class="row-odd"><td><p>Sprinkler(1)</p></td>
<td><p>0.5</p></td>
<td><p>0.1</p></td>
</tr>
</tbody>
</table>
</dd>
<dt>CPD of Rain:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 29%" />
<col style="width: 35%" />
<col style="width: 35%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>Cloudy</p></td>
<td><p>Cloudy(0)</p></td>
<td><p>Cloudy(1)</p></td>
</tr>
<tr class="row-even"><td><p>Rain(0)</p></td>
<td><p>0.8</p></td>
<td><p>0.2</p></td>
</tr>
<tr class="row-odd"><td><p>Rain(1)</p></td>
<td><p>0.2</p></td>
<td><p>0.8</p></td>
</tr>
</tbody>
</table>
</dd>
<dt>CPD of Wet_Grass:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>Sprinkler</p></td>
<td><p>Sprinkler(0)</p></td>
<td><p>Sprinkler(0)</p></td>
<td><p>Sprinkler(1)</p></td>
<td><p>Sprinkler(1)</p></td>
</tr>
<tr class="row-even"><td><p>Rain</p></td>
<td><p>Rain(0)</p></td>
<td><p>Rain(1)</p></td>
<td><p>Rain(0)</p></td>
<td><p>Rain(1)</p></td>
</tr>
<tr class="row-odd"><td><p>Wet_Grass(0)</p></td>
<td><p>1.0</p></td>
<td><p>0.1</p></td>
<td><p>0.1</p></td>
<td><p>0.01</p></td>
</tr>
<tr class="row-even"><td><p>Wet_Grass(1)</p></td>
<td><p>0.0</p></td>
<td><p>0.9</p></td>
<td><p>0.9</p></td>
<td><p>0.99</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>
<p>Lets generate more samples and learn again the parameters. You will see that these results are much closer to the true values.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">bnlearn</span><span class="o">.</span><span class="n">sampling</span><span class="p">(</span><span class="n">DAG</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="n">DAG_update</span> <span class="o">=</span> <span class="n">bnlearn</span><span class="o">.</span><span class="n">parameter_learning</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">DAG</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="example-parameter-learning-2">
<h3>Example Parameter learning 2<a class="headerlink" href="#example-parameter-learning-2" title="Permalink to this headline">¶</a></h3>
<p>Lets try out a more complexer model. We need both a directed acycle graph (DAG) and dataset with the same variables.
So again, the idea is to link the dataset with the DAG.</p>
<p>Let’s bring in the <strong>asia</strong> dataset.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">bnlearn</span>

<span class="c1"># Load asia data set</span>
<span class="n">DAG</span> <span class="o">=</span> <span class="n">bnlearn</span><span class="o">.</span><span class="n">import_DAG</span><span class="p">(</span><span class="s1">&#39;asia&#39;</span><span class="p">)</span>
<span class="c1"># Plot</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">bnlearn</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">DAG</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-default" id="id2">
<img alt="_images/fig2a_asia_groundtruth.png" src="_images/fig2a_asia_groundtruth.png" />
<p class="caption"><span class="caption-text">DAG of the Asia data set.</span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate samples</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">bnlearn</span><span class="o">.</span><span class="n">sampling</span><span class="p">(</span><span class="n">DAG</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>

<span class="c1"># Learn parameters</span>
<span class="n">DAG_update</span> <span class="o">=</span> <span class="n">bnlearn</span><span class="o">.</span><span class="n">parameter_learning</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">DAG</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
<p>This DAG is now updated with parameters which is great because it opens many possibilities in terms of inference or you can start sampling any number of samples you desire.</p>
<dl>
<dt>CPD of asia:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 56%" />
<col style="width: 44%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>asia(0)</p></td>
<td><p>0.055</p></td>
</tr>
<tr class="row-even"><td><p>asia(1)</p></td>
<td><p>0.944</p></td>
</tr>
</tbody>
</table>
</dd>
<dt>CPD of bronc:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>smoke</p></td>
<td><p>smoke(0)</p></td>
<td><p>smoke(1)</p></td>
</tr>
<tr class="row-even"><td><p>bronc(0)</p></td>
<td><p>0.585</p></td>
<td><p>0.319</p></td>
</tr>
<tr class="row-odd"><td><p>bronc(1)</p></td>
<td><p>0.414</p></td>
<td><p>0.680</p></td>
</tr>
</tbody>
</table>
</dd>
<dt>CPD of dysp:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 17%" />
<col style="width: 21%" />
<col style="width: 21%" />
<col style="width: 21%" />
<col style="width: 21%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>bronc</p></td>
<td><p>bronc(0)</p></td>
<td><p>bronc(0)</p></td>
<td><p>bronc(1)</p></td>
<td><p>bronc(1)</p></td>
</tr>
<tr class="row-even"><td><p>either</p></td>
<td><p>either(0)</p></td>
<td><p>either(1)</p></td>
<td><p>either(0)</p></td>
<td><p>either(1)</p></td>
</tr>
<tr class="row-odd"><td><p>dysp(0)</p></td>
<td><p>0.714</p></td>
<td><p>0.787</p></td>
<td><p>0.586</p></td>
<td><p>0.123</p></td>
</tr>
<tr class="row-even"><td><p>dysp(1)</p></td>
<td><p>0.285</p></td>
<td><p>0.212</p></td>
<td><p>0.413</p></td>
<td><p>0.876</p></td>
</tr>
</tbody>
</table>
</dd>
<dt>CPD of either:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 23%" />
<col style="width: 19%" />
<col style="width: 19%" />
<col style="width: 19%" />
<col style="width: 19%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>lung</p></td>
<td><p>lung(0)</p></td>
<td><p>lung(0)</p></td>
<td><p>lung(1)</p></td>
<td><p>lung(1)</p></td>
</tr>
<tr class="row-even"><td><p>tub</p></td>
<td><p>tub(0)</p></td>
<td><p>tub(1)</p></td>
<td><p>tub(0)</p></td>
<td><p>tub(1)</p></td>
</tr>
<tr class="row-odd"><td><p>either(0)</p></td>
<td><p>0.507</p></td>
<td><p>0.837</p></td>
<td><p>0.642</p></td>
<td><p>0.012</p></td>
</tr>
<tr class="row-even"><td><p>either(1)</p></td>
<td><p>0.492</p></td>
<td><p>0.1625</p></td>
<td><p>0.357</p></td>
<td><p>0.987</p></td>
</tr>
</tbody>
</table>
</dd>
<dt>CPD of lung:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 31%" />
<col style="width: 34%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>smoke</p></td>
<td><p>smoke(0)</p></td>
<td><p>smoke(1)</p></td>
</tr>
<tr class="row-even"><td><p>lung(0)</p></td>
<td><p>0.132</p></td>
<td><p>0.0537</p></td>
</tr>
<tr class="row-odd"><td><p>lung(1)</p></td>
<td><p>0.867</p></td>
<td><p>0.9462</p></td>
</tr>
</tbody>
</table>
</dd>
<dt>CPD of smoke:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 59%" />
<col style="width: 41%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>smoke(0)</p></td>
<td><p>0.498</p></td>
</tr>
<tr class="row-even"><td><p>smoke(1)</p></td>
<td><p>0.501</p></td>
</tr>
</tbody>
</table>
</dd>
<dt>CPD of tub:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 31%" />
<col style="width: 35%" />
<col style="width: 35%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>asia</p></td>
<td><p>asia(0)</p></td>
<td><p>asia(1)</p></td>
</tr>
<tr class="row-even"><td><p>tub(0)</p></td>
<td><p>0.418</p></td>
<td><p>0.0336</p></td>
</tr>
<tr class="row-odd"><td><p>tub(1)</p></td>
<td><p>0.581</p></td>
<td><p>0.9663</p></td>
</tr>
</tbody>
</table>
</dd>
<dt>CPD of xray:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 29%" />
<col style="width: 35%" />
<col style="width: 35%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>either</p></td>
<td><p>either(0)</p></td>
<td><p>either(1)</p></td>
</tr>
<tr class="row-even"><td><p>xray(0)</p></td>
<td><p>0.7693</p></td>
<td><p>0.070</p></td>
</tr>
<tr class="row-odd"><td><p>xray(1)</p></td>
<td><p>0.230</p></td>
<td><p>0.929</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Inference.html" class="btn btn-neutral float-right" title="Inference" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="Structure learning.html" class="btn btn-neutral float-left" title="Structure learning" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Erdogan Taskesen

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>